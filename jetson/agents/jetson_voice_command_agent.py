import requests
import sounddevice as sd
import numpy as np
import whisper
from langchain.prompts import PromptTemplate
from langchain.llms import Ollama
from langchain.chains import LLMChain
import time
import json
import os

# --- Configuration ---
MCP_AUDIO_FILE = "/app/data/audio/voice_command.wav"
SAMPLE_RATE = 16000
RECORD_SECONDS = 5
N8N_COMMAND_WEBHOOK = "http://raspberrypi:5678/webhook/jetson_command"

# Ollama local (Jetson)
LLM_MODEL = "llama3"  # ou "mistral", "phi3", selon ce que tu as charg√© avec Ollama

# --- Initialisation Whisper ---
whisper_model = whisper.load_model("base")

# --- Initialisation LLM LangChain ---
template = """
Tu es un assistant embarqu√© dans un Jetson Orin. 
Ton r√¥le est d'interpr√©ter des commandes vocales humaines et de les traduire en JSON simple.

Voici quelques exemples :
- "red√©marre le micro" -> {{"command": "restart_agent", "target": "audio"}}
- "red√©marre la cam√©ra" -> {{"command": "restart_agent", "target": "camera"}}
- "√©teins-toi" -> {{"command": "shutdown"}}
- "red√©marre-toi" -> {{"command": "reboot"}}

Commande √† interpr√©ter : "{user_input}"

R√©ponds UNIQUEMENT en JSON.
"""

prompt = PromptTemplate(template=template, input_variables=["user_input"])
llm = Ollama(model=LLM_MODEL)
chain = LLMChain(prompt=prompt, llm=llm)

# --- Fonctions ---

def record_audio(filename=MCP_AUDIO_FILE, duration=RECORD_SECONDS):
    """Enregistre la voix depuis le micro."""
    print("üéôÔ∏è Parlez maintenant...")
    data = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')
    sd.wait()
    sd.play(np.zeros(1000))  # petit "clic" silence pour √©viter un bruit r√©siduel
    import wave
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(data.tobytes())
    print(f"‚úÖ Audio enregistr√© : {filename}")
    return filename

def transcribe_audio(filename):
    """Transcrit l'audio en texte."""
    result = whisper_model.transcribe(filename, language="fr")
    text = result["text"].strip()
    print(f"üó£Ô∏è Transcription : {text}")
    return text

def interpret_command(text):
    """Envoie le texte au LLM pour extraire une commande JSON."""
    response = chain.run(user_input=text)
    print(f"ü§ñ Interpr√©tation brute : {response}")
    try:
        cmd = json.loads(response)
        return cmd
    except json.JSONDecodeError:
        print("‚ö†Ô∏è Erreur : sortie LLM non JSON.")
        return None

def send_command_to_n8n(command_dict):
    """Envoie la commande √† n8n via le webhook."""
    try:
        resp = requests.post(N8N_COMMAND_WEBHOOK, json=command_dict)
        print(f"üì° Commande envoy√©e √† n8n : {command_dict}")
        print(f"‚úÖ R√©ponse n8n : {resp.text}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur d‚Äôenvoi : {e}")

def voice_command_loop():
    """Boucle principale de commande vocale."""
    print("üéß Agent de commande vocale actif. Dites une commande (Ctrl+C pour quitter).")
    while True:
        try:
            filename = record_audio()
            text = transcribe_audio(filename)
            if text:
                cmd = interpret_command(text)
                if cmd:
                    send_command_to_n8n(cmd)
            time.sleep(2)
        except KeyboardInterrupt:
            print("\nüõë Arr√™t de l‚Äôagent vocal.")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur dans la boucle : {e}")
            time.sleep(5)

if __name__ == "__main__":
    voice_command_loop()
